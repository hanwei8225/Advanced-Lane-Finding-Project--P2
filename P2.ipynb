{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  First，import some package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T14:22:48.718246Z",
     "start_time": "2019-09-23T14:22:48.389940Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second,I'll creat some tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T14:45:30.205937Z",
     "start_time": "2019-09-23T14:45:30.190310Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_image(filepath):\n",
    "    return cv2.imread(filepath)\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def gaussian_smoothing(gray_img,kernel_size = 5):\n",
    "\n",
    "    return cv2.GaussianBlur(gray_img,(kernel_size, kernel_size),0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_outside_line(img,vertices,color=[0, 0, 255], thickness=3):\n",
    "    cv2.line(img,tuple(vertices[0][0]),tuple(vertices[0][1]),[0,255,0],thickness)\n",
    "    cv2.line(img,tuple(vertices[0][2]),tuple(vertices[0][3]),[0,255,0],thickness)\n",
    "    cv2.line(img,tuple(vertices[0][1]),tuple(vertices[0][2]),[0,255,0],thickness)\n",
    "    cv2.line(img,tuple(vertices[0][4]),tuple(vertices[0][5]),[0,255,0],thickness)\n",
    "    cv2.line(img,tuple(vertices[0][5]),tuple(vertices[0][6]),[0,255,0],thickness)\n",
    "    \n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T14:46:59.432422Z",
     "start_time": "2019-09-23T14:46:59.418823Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_images(files = '../camera_cal/calibration*.jpg'):\n",
    "    '''\n",
    "    获取校准文件数组\n",
    "    '''\n",
    "    return glob.glob(files)\n",
    "\n",
    "\n",
    "\n",
    "def get_points(images,point_size = (9,6)):\n",
    "    '''\n",
    "    获取校准点的数组\n",
    "    '''\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = read_image(fname)\n",
    "        gray = grayscale(img)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, point_size,None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    return objpoints,imgpoints\n",
    "\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    '''\n",
    "    获取校准后的图像\n",
    "    '''\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist,mtx,dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  create a thresholded binary image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:58:44.822595Z",
     "start_time": "2019-09-23T15:58:44.803700Z"
    }
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(gray_img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    '''\n",
    "    获取某个维度上经过索贝尔算子获得的边缘图\n",
    "    '''\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    if orient == \"x\":\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0,ksize = sobel_kernel)\n",
    "    elif orient == \"y\":\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1,ksize = sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    mask = (scaled_sobel > thresh_min) & (scaled_sobel < thresh_max)\n",
    "    binary_output = np.zeros_like(gray_img)\n",
    "    binary_output[mask] = 1\n",
    "    \n",
    "    return binary_output\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(gray_img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    '''\n",
    "    获取x轴和y轴合成的梯度大小在范围内的边缘图\n",
    "    '''\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0,ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1,ksize = sobel_kernel)\n",
    "    sobel = np.sqrt(sobelx ** 2+ sobely ** 2)\n",
    "    scaled_sobel = np.uint8(255*sobel/np.max(sobel))\n",
    "    mask = (scaled_sobel > mag_thresh[0]) & (scaled_sobel < mag_thresh[1])\n",
    "    mag_binary = np.zeros_like(gray_img)\n",
    "    mag_binary[mask] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(gray_img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    '''\n",
    "    获取梯度角度在一定范围内的边缘图\n",
    "    '''\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0,ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1,ksize = sobel_kernel)\n",
    "    # sobel = np.sqrt(sobelx ** 2+ sobely ** 2)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    arctan = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    mask = (arctan > thresh[0]) & (arctan < thresh[1])\n",
    "    dir_binary = np.zeros_like(gray_img) # Remove this line\n",
    "    dir_binary[mask] = 1\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T16:05:35.458091Z",
     "start_time": "2019-09-23T16:05:35.440383Z"
    }
   },
   "outputs": [],
   "source": [
    "def hls_select(img,channel = \"S\", thresh=(0, 255)):\n",
    "    '''\n",
    "    获取hls空间某个维度的阈值\n",
    "    '''\n",
    "\n",
    "    hls_image = cv2.cvtColor(img,cv2.COLOR_BGR2HLS)\n",
    "    if channel ==  \"S\":\n",
    "        mask = (hls_image[:,:,2] > thresh[0]) &  (hls_image[:,:,2] <= thresh[1])\n",
    "    elif channel ==  \"H\":\n",
    "        mask = (hls_image[:,:,0] > thresh[0]) &  (hls_image[:,:,0] <= thresh[1])\n",
    "    elif channel == \"L\":\n",
    "        mask = (hls_image[:,:,1] > thresh[0]) &  (hls_image[:,:,1] <= thresh[1])\n",
    "    else:\n",
    "        return None\n",
    "    binary_output = np.zeros_like(hls_image[:,:,2]) # placeholder line\n",
    "    binary_output[mask] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def bgr_select(image,channel = \"R\",thresh = (0,255)):\n",
    "    '''\n",
    "    获取BGR空间某个维度的阈值\n",
    "    '''\n",
    "    if channel ==  \"R\":\n",
    "        mask = (image[:,:,2] > thresh[0]) &  (image[:,:,2] <= thresh[1])\n",
    "    elif channel ==  \"B\":\n",
    "        mask = (image[:,:,0] > thresh[0]) &  (image[:,:,0] <= thresh[1])\n",
    "    elif channel == \"G\":\n",
    "        mask = (image[:,:,1] > thresh[0]) &  (image[:,:,1] <= thresh[1])\n",
    "    else:\n",
    "        return None\n",
    "    binary_output = np.zeros_like(image[:,:,2]) # placeholder line\n",
    "    binary_output[mask] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Rectify binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recity_unwarp(undist_img, src, dist, mtx, dist):\n",
    "    '''\n",
    "    将校正后的图像根据src和dist转化为鸟瞰图\n",
    "    '''\n",
    "\n",
    "\n",
    "#         src = np.float32([p1,p2,p3,p4])\n",
    "#         dst = np.float32([[100,100],[250,100],[250,250],[100,250]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_R = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(undist_img, M, undist_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T15:43:10.936399Z",
     "start_time": "2019-09-24T15:43:10.899384Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped,nwindows = 9,margin = 100,minpix = 50):\n",
    "    '''\n",
    "    找到所有的有效的左右车道线坐标值\n",
    "    '''\n",
    "    # 获取图像下半部分像素值y轴上相加的直方图\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # 找到图像中点，将其分为左右两部分\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    \n",
    "    # 返回每一边最大直方图顶点对应的索引，\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # 超参数\n",
    "    # 分成几个窗口\n",
    "    # nwindows = 9\n",
    "    # 窗口的宽度+/- margin\n",
    "    # margin = 100\n",
    "    #寻找中心线的最小像素数\n",
    "    # minpix = 50\n",
    "\n",
    "    # 求出窗口的高度\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # 返回二值图非0元素的X坐标元组，y坐标元组\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # 当前窗口中心线的位置，在每个窗口中更新\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # 用来储存每个窗口的左右车道的非零像素的索引\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # 对于每个窗口\n",
    "    for window in range(nwindows):\n",
    "        #找到y边界\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "\n",
    "        #找到x边界\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "\n",
    "        # 画出窗口的边界线\n",
    "#         cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "#         cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # 获取窗口区域的值，分别是从y轴和x轴限制\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        # 将获取到的不为0的x的坐标索引储存\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "\n",
    "        # 如果获取到的像素点数目大于阈值，则设置下个窗口的中点值，中点值为有效坐标的平均值\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "\n",
    "    # 有效像素列表进行拼接，拼接为np数组，列表为x和y的坐标数组中的索引\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # 从坐标数组中中获取对应的像素索引的x和y的坐标\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    '''\n",
    "    拟合左右曲线，以Y轴为自变量，X轴为因变量，\n",
    "    因为车道线相对来说是比较垂直，以X轴为自变量可能不太好拟合，会存在一个x对应几个y，所有以y为自变量\n",
    "    '''\n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    # Generate x and y values for plotting\n",
    "    # 获取x轴\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    # 获取左右的多项式，fit为系数，ploty为y值,是y为自变量\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "\n",
    "def search_around_poly(binary_warped,left_fit,right_fit,margin = 100):\n",
    "    '''\n",
    "    通过将拟合的曲线左右延伸来获取下一帧图像的优先检测区域，若检测不到，可以再次从传统窗口检测\n",
    "    \n",
    "    '''\n",
    "    # 超参数，设置拟合线左右的边距 margin = 100\n",
    "    \n",
    "\n",
    "    # 获取有效像素\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_pixels(ploty, left_fit, right_fit):\n",
    "    '''\n",
    "    y以像素为单位计算曲率\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # 通过公式计算曲率\n",
    "    left_curverad =((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    \n",
    "    right_curverad = ((1 + (2 * right_fit[0] * y_eval + right_fit[1] ) ** 2)**1.5)/np.absolute(2*right_fit[0])\n",
    "    \n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "def measure_curvature_real(binary_warped,ploty, left_fit_cr, right_fit_cr,ym_per_pix = 30/720,xm_per_pix = 3.7/700):\n",
    "    '''\n",
    "    y以现实距离计算曲率\n",
    "    '''\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # 利用公式计算曲率\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    #计算摄像头中心线和车道中心线的距离\n",
    "    \n",
    "    cam_middle = binary_warped.shape[0]/2 * xm_per_pix\n",
    "    \n",
    "    \n",
    "    road_left = (left_fit_cr[0] * (y_eval ** 2)) + (left_fit_cr[1] * y_eval) + left_fit_cr[2]\n",
    "    road_right = (right_fit_cr[0] * (y_eval ** 2)) + (right_fit_cr[1] * y_eval) + right_fit_cr[2]\n",
    "    road_middle = (road_right+road_left)/2 * xm_per_pix\n",
    "    \n",
    "    distance = cam_middle - road_middle\n",
    "    \n",
    "    \n",
    "    return left_curverad, right_curverad,distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_draw(binary_warped,left_fitx,right_fitx, ploty):\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    # 获取窗口左右的边界\n",
    "\n",
    "    windows_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])  #将x和y组合成2维的数组，转置为（x，y）\n",
    "    windows_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])  #转置后再反转\n",
    "    windows = np.hstack((windows_left, windows_right)) #将点数组合并\n",
    "    \n",
    "    \n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "\n",
    "    cv2.fillPoly(window_img, np.int_([windows]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    cv2.circle(out_img,windows_left , 1, (0, 0, 255), 4)\n",
    "    cv2.circle(out_img,windows_right , 1, (0, 0, 255), 4)\n",
    "    ## End visualization steps ##\n",
    "    return out_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output after processing\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
